{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "3fa00e96d39b630c273b53b61e0aba6e86167ba910e5d5375f971cdfa7b59242"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Description"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Demonstration on how the outliers are being removed from the database on a single parameter DF. The same principle is followed on the OutliersRemovalTools class. The only difference is that on the class, the methods updates the preprocessed_df attribute. \n",
    "\n",
    "Original docstrings from the class:\n",
    "\n",
    "        '''\n",
    "        Method that will remove all of the values that are lower or higher than\n",
    "        the sum of the average + - std_factor * std dev.\n",
    "        The average and std dev is considered to be different on each station and on each parameter.\n",
    "        The outliers will be replaced with a NaN.\n",
    "\n",
    "        :param std_factor: factor to which multiply the std dev\n",
    "        :return: updates the preprocessed_df class attribute\n",
    "        '''"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing the libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "source": [
    "## Reading the .csv preprocessed files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             FECHAHORA    ATM    OBL   LPIN    SFE    TLA    VAL    CEN  \\\n",
       "0  2016-01-01 00:00:00  1.471  1.010  7.165  3.513  2.215  0.240  0.180   \n",
       "1  2016-01-01 01:00:00  2.653  1.069  6.272  4.953  1.835  0.387  0.736   \n",
       "2  2016-01-01 02:00:00  2.712  2.026  7.088  4.286  3.287  0.822  0.948   \n",
       "3  2016-01-01 03:00:00  2.099  3.375  5.977  4.577  4.691  1.414  2.207   \n",
       "4  2016-01-01 04:00:00  2.019  2.195  5.833  5.180  4.873  1.277  4.192   \n",
       "\n",
       "     AGU    LDO    MIR       FECHA      HORA  \n",
       "0  0.615  2.830  4.720  2016-01-01  00:00:00  \n",
       "1  1.177  2.150  5.800  2016-01-01  01:00:00  \n",
       "2  1.594  1.957  7.098  2016-01-01  02:00:00  \n",
       "3  2.074  1.956  6.499  2016-01-01  03:00:00  \n",
       "4  1.601  3.221  4.743  2016-01-01  04:00:00  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FECHAHORA</th>\n      <th>ATM</th>\n      <th>OBL</th>\n      <th>LPIN</th>\n      <th>SFE</th>\n      <th>TLA</th>\n      <th>VAL</th>\n      <th>CEN</th>\n      <th>AGU</th>\n      <th>LDO</th>\n      <th>MIR</th>\n      <th>FECHA</th>\n      <th>HORA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-01 00:00:00</td>\n      <td>1.471</td>\n      <td>1.010</td>\n      <td>7.165</td>\n      <td>3.513</td>\n      <td>2.215</td>\n      <td>0.240</td>\n      <td>0.180</td>\n      <td>0.615</td>\n      <td>2.830</td>\n      <td>4.720</td>\n      <td>2016-01-01</td>\n      <td>00:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01-01 01:00:00</td>\n      <td>2.653</td>\n      <td>1.069</td>\n      <td>6.272</td>\n      <td>4.953</td>\n      <td>1.835</td>\n      <td>0.387</td>\n      <td>0.736</td>\n      <td>1.177</td>\n      <td>2.150</td>\n      <td>5.800</td>\n      <td>2016-01-01</td>\n      <td>01:00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01-01 02:00:00</td>\n      <td>2.712</td>\n      <td>2.026</td>\n      <td>7.088</td>\n      <td>4.286</td>\n      <td>3.287</td>\n      <td>0.822</td>\n      <td>0.948</td>\n      <td>1.594</td>\n      <td>1.957</td>\n      <td>7.098</td>\n      <td>2016-01-01</td>\n      <td>02:00:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01-01 03:00:00</td>\n      <td>2.099</td>\n      <td>3.375</td>\n      <td>5.977</td>\n      <td>4.577</td>\n      <td>4.691</td>\n      <td>1.414</td>\n      <td>2.207</td>\n      <td>2.074</td>\n      <td>1.956</td>\n      <td>6.499</td>\n      <td>2016-01-01</td>\n      <td>03:00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01-01 04:00:00</td>\n      <td>2.019</td>\n      <td>2.195</td>\n      <td>5.833</td>\n      <td>5.180</td>\n      <td>4.873</td>\n      <td>1.277</td>\n      <td>4.192</td>\n      <td>1.601</td>\n      <td>3.221</td>\n      <td>4.743</td>\n      <td>2016-01-01</td>\n      <td>04:00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#defining paths\n",
    "preprocessed_path = r\"C:\\Users\\victo\\PycharmProjects\\DataScienceProj\\DS-Proj\\Air_modelling\\data\\preprocessed_data\\Parameters\"\n",
    "os.chdir(preprocessed_path)\n",
    "preprocessed_fileslist = os.listdir()\n",
    "#calling the first .csv file to work on \n",
    "#in this case, it will be CO data\n",
    "\n",
    "#select the file or files to apply \n",
    "raw_P_df = pd.read_csv(preprocessed_fileslist[0])\n",
    "raw_P_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     AGU    ATM    CEN    LDO   LPIN    MIR    OBL    SFE    TLA    VAL\n",
       "0  0.615  1.471  0.180  2.830  7.165  4.720  1.010  3.513  2.215  0.240\n",
       "1  1.177  2.653  0.736  2.150  6.272  5.800  1.069  4.953  1.835  0.387\n",
       "2  1.594  2.712  0.948  1.957  7.088  7.098  2.026  4.286  3.287  0.822\n",
       "3  2.074  2.099  2.207  1.956  5.977  6.499  3.375  4.577  4.691  1.414\n",
       "4  1.601  2.019  4.192  3.221  5.833  4.743  2.195  5.180  4.873  1.277"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGU</th>\n      <th>ATM</th>\n      <th>CEN</th>\n      <th>LDO</th>\n      <th>LPIN</th>\n      <th>MIR</th>\n      <th>OBL</th>\n      <th>SFE</th>\n      <th>TLA</th>\n      <th>VAL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.615</td>\n      <td>1.471</td>\n      <td>0.180</td>\n      <td>2.830</td>\n      <td>7.165</td>\n      <td>4.720</td>\n      <td>1.010</td>\n      <td>3.513</td>\n      <td>2.215</td>\n      <td>0.240</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.177</td>\n      <td>2.653</td>\n      <td>0.736</td>\n      <td>2.150</td>\n      <td>6.272</td>\n      <td>5.800</td>\n      <td>1.069</td>\n      <td>4.953</td>\n      <td>1.835</td>\n      <td>0.387</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.594</td>\n      <td>2.712</td>\n      <td>0.948</td>\n      <td>1.957</td>\n      <td>7.088</td>\n      <td>7.098</td>\n      <td>2.026</td>\n      <td>4.286</td>\n      <td>3.287</td>\n      <td>0.822</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.074</td>\n      <td>2.099</td>\n      <td>2.207</td>\n      <td>1.956</td>\n      <td>5.977</td>\n      <td>6.499</td>\n      <td>3.375</td>\n      <td>4.577</td>\n      <td>4.691</td>\n      <td>1.414</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.601</td>\n      <td>2.019</td>\n      <td>4.192</td>\n      <td>3.221</td>\n      <td>5.833</td>\n      <td>4.743</td>\n      <td>2.195</td>\n      <td>5.180</td>\n      <td>4.873</td>\n      <td>1.277</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#eliminate columns we don't need for the moment such as FECHA and HORA\n",
    "raw_P_df.columns.values\n",
    "P_df = raw_P_df[['AGU', 'ATM', 'CEN', 'LDO', 'LPIN', 'MIR', 'OBL', 'SFE', 'TLA', 'VAL']]\n",
    "P_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert P_df into ndarray\n",
    "P_arr = P_df.to_numpy()\n",
    "\n",
    "#Create fvout_arr (first value out array) which has all the values but the first one\n",
    "fvout_arr = P_arr[1:,:]\n",
    "\n",
    "#Create a lvout_arr (last value out array) which has all the values but the last one \n",
    "lvout_arr = P_arr[:-1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a delta_arr array that stores the value of the diff between fvout and lvout\n",
    "delta_arr = fvout_arr - lvout_arr\n",
    "\n",
    "#obtain the mean and std of the delta_arr values\n",
    "mean_delta_arr = np.nanmean(delta_arr)\n",
    "std_delta_arr = np.nanstd(delta_arr)\n",
    "\n",
    "#create a std_factor var to specify the span of the scalar size\n",
    "std_factor = 3 \n",
    "\n",
    "#hscalar represents the highest value our parameter can have before we remove it \n",
    "#lscalar works the same but with the lowest value\n",
    "hscalar = mean_delta_arr + std_factor * std_delta_arr \n",
    "lscalar = mean_delta_arr - std_factor * std_delta_arr \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aabc9785b615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#IMPORTANT!!: add a + 1 on the row index as we are going to delete the values from the main ndarray and not from delta_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0moutliers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_arr\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlscalar\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdelta_arr\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mhscalar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mcoordinates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutliers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutliers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#This one is a merge between the two previous steps but taking in consideration the index of the original array which has an extra value \n",
    "\n",
    "#get the index of the elements whose values are gt hscalar or lt lscalar\n",
    "#IMPORTANT!!: add a + 1 on the row index as we are going to delete the values from the main ndarray and not from delta_arr\n",
    "\n",
    "outliers = np.where((delta_arr <= lscalar) | (delta_arr >= hscalar))\n",
    "coordinates = list(zip(outliers[0] + 1, outliers[1]))\n",
    "\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'coordinates' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a69d4a759cbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#total of data removed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_to_remove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Percentage of data removed for this matrix: {0:.2f}%'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_remove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'coordinates' is not defined"
     ]
    }
   ],
   "source": [
    "#total of data removed\n",
    "data_to_remove = len(coordinates)/(P_arr.shape[0]*10)\n",
    "print('Percentage of data removed for this matrix: {0:.2f}%'.format(data_to_remove))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing outliers with nan\n",
    "for i in range(len(coordinates)):\n",
    "    P_arr[coordinates[i]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     AGU    ATM    CEN    LDO   LPIN    MIR    OBL    SFE    TLA    VAL\n",
       "0  0.615  1.471  0.180  2.830  7.165  4.720  1.010  3.513  2.215  0.240\n",
       "1  1.177  2.653  0.736  2.150  6.272  5.800  1.069    NaN  1.835  0.387\n",
       "2  1.594  2.712  0.948  1.957  7.088  7.098  2.026  4.286    NaN  0.822\n",
       "3  2.074  2.099  2.207  1.956  5.977  6.499    NaN  4.577    NaN  1.414\n",
       "4  1.601  2.019    NaN  3.221  5.833    NaN  2.195  5.180  4.873  1.277"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGU</th>\n      <th>ATM</th>\n      <th>CEN</th>\n      <th>LDO</th>\n      <th>LPIN</th>\n      <th>MIR</th>\n      <th>OBL</th>\n      <th>SFE</th>\n      <th>TLA</th>\n      <th>VAL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.615</td>\n      <td>1.471</td>\n      <td>0.180</td>\n      <td>2.830</td>\n      <td>7.165</td>\n      <td>4.720</td>\n      <td>1.010</td>\n      <td>3.513</td>\n      <td>2.215</td>\n      <td>0.240</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.177</td>\n      <td>2.653</td>\n      <td>0.736</td>\n      <td>2.150</td>\n      <td>6.272</td>\n      <td>5.800</td>\n      <td>1.069</td>\n      <td>NaN</td>\n      <td>1.835</td>\n      <td>0.387</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.594</td>\n      <td>2.712</td>\n      <td>0.948</td>\n      <td>1.957</td>\n      <td>7.088</td>\n      <td>7.098</td>\n      <td>2.026</td>\n      <td>4.286</td>\n      <td>NaN</td>\n      <td>0.822</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.074</td>\n      <td>2.099</td>\n      <td>2.207</td>\n      <td>1.956</td>\n      <td>5.977</td>\n      <td>6.499</td>\n      <td>NaN</td>\n      <td>4.577</td>\n      <td>NaN</td>\n      <td>1.414</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.601</td>\n      <td>2.019</td>\n      <td>NaN</td>\n      <td>3.221</td>\n      <td>5.833</td>\n      <td>NaN</td>\n      <td>2.195</td>\n      <td>5.180</td>\n      <td>4.873</td>\n      <td>1.277</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#create the new df with outliers removed\n",
    "processed_P_df = pd.DataFrame(columns=P_df.columns.values, data=P_arr)\n",
    "processed_P_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       AGU    ATM    CEN    LDO   LPIN    MIR    OBL    SFE  \\\n",
       "FECHAHORA                                                                     \n",
       "2016-01-01 00:00:00  0.615  1.471  0.180  2.830  7.165  4.720  1.010  3.513   \n",
       "2016-01-01 01:00:00  1.177  2.653  0.736  2.150  6.272  5.800  1.069    NaN   \n",
       "2016-01-01 02:00:00  1.594  2.712  0.948  1.957  7.088  7.098  2.026  4.286   \n",
       "2016-01-01 03:00:00  2.074  2.099  2.207  1.956  5.977  6.499    NaN  4.577   \n",
       "2016-01-01 04:00:00  1.601  2.019    NaN  3.221  5.833    NaN  2.195  5.180   \n",
       "...                    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2019-12-31 19:00:00    NaN    NaN  0.378  1.449  0.854    NaN    NaN  0.453   \n",
       "2019-12-31 20:00:00    NaN    NaN  0.551  1.807  1.532    NaN    NaN  0.440   \n",
       "2019-12-31 21:00:00    NaN    NaN  0.970  2.136  2.255    NaN    NaN  0.494   \n",
       "2019-12-31 22:00:00    NaN    NaN  1.268  2.029  1.481    NaN    NaN  0.510   \n",
       "2019-12-31 23:00:00    NaN    NaN  0.614  1.398  0.643    NaN    NaN  0.054   \n",
       "\n",
       "                       TLA    VAL       FECHA      HORA  \n",
       "FECHAHORA                                                \n",
       "2016-01-01 00:00:00  2.215  0.240  2016-01-01  00:00:00  \n",
       "2016-01-01 01:00:00  1.835  0.387  2016-01-01  01:00:00  \n",
       "2016-01-01 02:00:00    NaN  0.822  2016-01-01  02:00:00  \n",
       "2016-01-01 03:00:00    NaN  1.414  2016-01-01  03:00:00  \n",
       "2016-01-01 04:00:00  4.873  1.277  2016-01-01  04:00:00  \n",
       "...                    ...    ...         ...       ...  \n",
       "2019-12-31 19:00:00    NaN  0.438  2019-12-31  19:00:00  \n",
       "2019-12-31 20:00:00    NaN  0.511  2019-12-31  20:00:00  \n",
       "2019-12-31 21:00:00    NaN  0.643  2019-12-31  21:00:00  \n",
       "2019-12-31 22:00:00    NaN  0.670  2019-12-31  22:00:00  \n",
       "2019-12-31 23:00:00    NaN  0.737  2019-12-31  23:00:00  \n",
       "\n",
       "[35064 rows x 12 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGU</th>\n      <th>ATM</th>\n      <th>CEN</th>\n      <th>LDO</th>\n      <th>LPIN</th>\n      <th>MIR</th>\n      <th>OBL</th>\n      <th>SFE</th>\n      <th>TLA</th>\n      <th>VAL</th>\n      <th>FECHA</th>\n      <th>HORA</th>\n    </tr>\n    <tr>\n      <th>FECHAHORA</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2016-01-01 00:00:00</th>\n      <td>0.615</td>\n      <td>1.471</td>\n      <td>0.180</td>\n      <td>2.830</td>\n      <td>7.165</td>\n      <td>4.720</td>\n      <td>1.010</td>\n      <td>3.513</td>\n      <td>2.215</td>\n      <td>0.240</td>\n      <td>2016-01-01</td>\n      <td>00:00:00</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 01:00:00</th>\n      <td>1.177</td>\n      <td>2.653</td>\n      <td>0.736</td>\n      <td>2.150</td>\n      <td>6.272</td>\n      <td>5.800</td>\n      <td>1.069</td>\n      <td>NaN</td>\n      <td>1.835</td>\n      <td>0.387</td>\n      <td>2016-01-01</td>\n      <td>01:00:00</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 02:00:00</th>\n      <td>1.594</td>\n      <td>2.712</td>\n      <td>0.948</td>\n      <td>1.957</td>\n      <td>7.088</td>\n      <td>7.098</td>\n      <td>2.026</td>\n      <td>4.286</td>\n      <td>NaN</td>\n      <td>0.822</td>\n      <td>2016-01-01</td>\n      <td>02:00:00</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 03:00:00</th>\n      <td>2.074</td>\n      <td>2.099</td>\n      <td>2.207</td>\n      <td>1.956</td>\n      <td>5.977</td>\n      <td>6.499</td>\n      <td>NaN</td>\n      <td>4.577</td>\n      <td>NaN</td>\n      <td>1.414</td>\n      <td>2016-01-01</td>\n      <td>03:00:00</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 04:00:00</th>\n      <td>1.601</td>\n      <td>2.019</td>\n      <td>NaN</td>\n      <td>3.221</td>\n      <td>5.833</td>\n      <td>NaN</td>\n      <td>2.195</td>\n      <td>5.180</td>\n      <td>4.873</td>\n      <td>1.277</td>\n      <td>2016-01-01</td>\n      <td>04:00:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2019-12-31 19:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.378</td>\n      <td>1.449</td>\n      <td>0.854</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.453</td>\n      <td>NaN</td>\n      <td>0.438</td>\n      <td>2019-12-31</td>\n      <td>19:00:00</td>\n    </tr>\n    <tr>\n      <th>2019-12-31 20:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.551</td>\n      <td>1.807</td>\n      <td>1.532</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.440</td>\n      <td>NaN</td>\n      <td>0.511</td>\n      <td>2019-12-31</td>\n      <td>20:00:00</td>\n    </tr>\n    <tr>\n      <th>2019-12-31 21:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.970</td>\n      <td>2.136</td>\n      <td>2.255</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.494</td>\n      <td>NaN</td>\n      <td>0.643</td>\n      <td>2019-12-31</td>\n      <td>21:00:00</td>\n    </tr>\n    <tr>\n      <th>2019-12-31 22:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.268</td>\n      <td>2.029</td>\n      <td>1.481</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.510</td>\n      <td>NaN</td>\n      <td>0.670</td>\n      <td>2019-12-31</td>\n      <td>22:00:00</td>\n    </tr>\n    <tr>\n      <th>2019-12-31 23:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.614</td>\n      <td>1.398</td>\n      <td>0.643</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.054</td>\n      <td>NaN</td>\n      <td>0.737</td>\n      <td>2019-12-31</td>\n      <td>23:00:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>35064 rows Ã— 12 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#adding date and time columns\n",
    "processed_P_df['FECHA'] = raw_P_df['FECHA']\n",
    "processed_P_df['HORA'] = raw_P_df['HORA']\n",
    "processed_P_df['FECHAHORA'] = raw_P_df['FECHAHORA']\n",
    "processed_P_df.set_index('FECHAHORA')"
   ]
  }
 ]
}