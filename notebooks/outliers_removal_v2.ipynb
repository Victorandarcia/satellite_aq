{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "3fa00e96d39b630c273b53b61e0aba6e86167ba910e5d5375f971cdfa7b59242"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Description"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Demonstration on how the outliers are being removed from the database on a single parameter DF. The same principle is followed on the OutliersRemovalTools class. The only difference is that on the class, the methods updates the preprocessed_df attribute. \n",
    "\n",
    "Original docstrings from the class:\n",
    "\n",
    "        '''\n",
    "        This is a modified version of the remove_std_outliers_v1 method that deletes outliers that fits the following statements:\n",
    "\n",
    "        There must be at least 2 consecutive values higher or lower than the 3 std dev scalar.\n",
    "        from those 2 consecutive values, one must have a negative value and the other a positive value in order to be removed.\n",
    "\n",
    "        :return: Updates the preprocessed_df attribute which then can be exported to a .csv file.\n",
    "        '''\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing the libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Reading the .csv preprocessed files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             FECHAHORA     ATM     OBL  LPIN     SFE     TLA    VAL     CEN  \\\n",
       "0  2016-01-01 00:00:00  146.95  197.67   NaN  115.54  143.40  17.08   86.12   \n",
       "1  2016-01-01 01:00:00  216.10  138.09   NaN   84.24  100.46  29.15   46.49   \n",
       "2  2016-01-01 02:00:00  113.44   98.79   NaN  135.39   82.05  30.89   63.93   \n",
       "3  2016-01-01 03:00:00   73.30   97.94   NaN  117.60  114.74  38.74   60.75   \n",
       "4  2016-01-01 04:00:00   52.55  134.39   NaN  164.68  118.83  51.48  108.09   \n",
       "\n",
       "     AGU     LDO     MIR       FECHA      HORA  \n",
       "0  49.92  174.04   69.75  2016-01-01  00:00:00  \n",
       "1  52.80  115.27   68.99  2016-01-01  01:00:00  \n",
       "2  52.71   99.00  117.70  2016-01-01  02:00:00  \n",
       "3  51.24   83.65  160.30  2016-01-01  03:00:00  \n",
       "4  58.84   49.70  180.89  2016-01-01  04:00:00  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FECHAHORA</th>\n      <th>ATM</th>\n      <th>OBL</th>\n      <th>LPIN</th>\n      <th>SFE</th>\n      <th>TLA</th>\n      <th>VAL</th>\n      <th>CEN</th>\n      <th>AGU</th>\n      <th>LDO</th>\n      <th>MIR</th>\n      <th>FECHA</th>\n      <th>HORA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-01 00:00:00</td>\n      <td>146.95</td>\n      <td>197.67</td>\n      <td>NaN</td>\n      <td>115.54</td>\n      <td>143.40</td>\n      <td>17.08</td>\n      <td>86.12</td>\n      <td>49.92</td>\n      <td>174.04</td>\n      <td>69.75</td>\n      <td>2016-01-01</td>\n      <td>00:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01-01 01:00:00</td>\n      <td>216.10</td>\n      <td>138.09</td>\n      <td>NaN</td>\n      <td>84.24</td>\n      <td>100.46</td>\n      <td>29.15</td>\n      <td>46.49</td>\n      <td>52.80</td>\n      <td>115.27</td>\n      <td>68.99</td>\n      <td>2016-01-01</td>\n      <td>01:00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01-01 02:00:00</td>\n      <td>113.44</td>\n      <td>98.79</td>\n      <td>NaN</td>\n      <td>135.39</td>\n      <td>82.05</td>\n      <td>30.89</td>\n      <td>63.93</td>\n      <td>52.71</td>\n      <td>99.00</td>\n      <td>117.70</td>\n      <td>2016-01-01</td>\n      <td>02:00:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01-01 03:00:00</td>\n      <td>73.30</td>\n      <td>97.94</td>\n      <td>NaN</td>\n      <td>117.60</td>\n      <td>114.74</td>\n      <td>38.74</td>\n      <td>60.75</td>\n      <td>51.24</td>\n      <td>83.65</td>\n      <td>160.30</td>\n      <td>2016-01-01</td>\n      <td>03:00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01-01 04:00:00</td>\n      <td>52.55</td>\n      <td>134.39</td>\n      <td>NaN</td>\n      <td>164.68</td>\n      <td>118.83</td>\n      <td>51.48</td>\n      <td>108.09</td>\n      <td>58.84</td>\n      <td>49.70</td>\n      <td>180.89</td>\n      <td>2016-01-01</td>\n      <td>04:00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#defining paths\n",
    "preprocessed_path = r\"C:\\Users\\victo\\PycharmProjects\\DataScienceProj\\DS-Proj\\Air_modelling\\data\\preprocessed_data\\Parameters\"\n",
    "os.chdir(preprocessed_path)\n",
    "preprocessed_fileslist = os.listdir()\n",
    "#calling the fifth .csv file to work on \n",
    "#in this case, it will be PM10 data\n",
    "\n",
    "#select the file or files to apply \n",
    "\n",
    "raw_P_df = pd.read_csv(preprocessed_fileslist[4])\n",
    "raw_P_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     AGU     ATM     CEN     LDO  LPIN     MIR     OBL     SFE     TLA    VAL\n",
       "0  49.92  146.95   86.12  174.04   NaN   69.75  197.67  115.54  143.40  17.08\n",
       "1  52.80  216.10   46.49  115.27   NaN   68.99  138.09   84.24  100.46  29.15\n",
       "2  52.71  113.44   63.93   99.00   NaN  117.70   98.79  135.39   82.05  30.89\n",
       "3  51.24   73.30   60.75   83.65   NaN  160.30   97.94  117.60  114.74  38.74\n",
       "4  58.84   52.55  108.09   49.70   NaN  180.89  134.39  164.68  118.83  51.48"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGU</th>\n      <th>ATM</th>\n      <th>CEN</th>\n      <th>LDO</th>\n      <th>LPIN</th>\n      <th>MIR</th>\n      <th>OBL</th>\n      <th>SFE</th>\n      <th>TLA</th>\n      <th>VAL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>49.92</td>\n      <td>146.95</td>\n      <td>86.12</td>\n      <td>174.04</td>\n      <td>NaN</td>\n      <td>69.75</td>\n      <td>197.67</td>\n      <td>115.54</td>\n      <td>143.40</td>\n      <td>17.08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>52.80</td>\n      <td>216.10</td>\n      <td>46.49</td>\n      <td>115.27</td>\n      <td>NaN</td>\n      <td>68.99</td>\n      <td>138.09</td>\n      <td>84.24</td>\n      <td>100.46</td>\n      <td>29.15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52.71</td>\n      <td>113.44</td>\n      <td>63.93</td>\n      <td>99.00</td>\n      <td>NaN</td>\n      <td>117.70</td>\n      <td>98.79</td>\n      <td>135.39</td>\n      <td>82.05</td>\n      <td>30.89</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>51.24</td>\n      <td>73.30</td>\n      <td>60.75</td>\n      <td>83.65</td>\n      <td>NaN</td>\n      <td>160.30</td>\n      <td>97.94</td>\n      <td>117.60</td>\n      <td>114.74</td>\n      <td>38.74</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>58.84</td>\n      <td>52.55</td>\n      <td>108.09</td>\n      <td>49.70</td>\n      <td>NaN</td>\n      <td>180.89</td>\n      <td>134.39</td>\n      <td>164.68</td>\n      <td>118.83</td>\n      <td>51.48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#eliminate columns we don't need for the moment such as FECHA and HORA\n",
    "raw_P_df.columns.values\n",
    "P_df = raw_P_df[['AGU', 'ATM', 'CEN', 'LDO', 'LPIN', 'MIR', 'OBL', 'SFE', 'TLA', 'VAL']]\n",
    "P_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert P_df into ndarray\n",
    "P_arr = P_df.to_numpy()\n",
    "\n",
    "#Create fvout_arr (first value out array) which has all the values but the first one\n",
    "fvout_arr = P_arr[1:,:]\n",
    "\n",
    "#Create a lvout_arr (last value out array) which has all the values but the last one \n",
    "lvout_arr = P_arr[:-1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a delta_arr array that stores the value of the diff between fvout and lvout\n",
    "delta_arr = fvout_arr - lvout_arr\n",
    "\n",
    "#obtain the mean and std of the delta_arr values by station\n",
    "mean_delta_arr = np.nanmean(delta_arr, axis=0)\n",
    "std_delta_arr = np.nanstd(delta_arr, axis=0)\n",
    "\n",
    "#create a std_factor var to specify the span of the scalar size\n",
    "std_factor = 3 \n",
    "\n",
    "#hscalar represents the highest value our parameter can have before we remove it \n",
    "#lscalar works the same but with the lowest value\n",
    "hscalar = mean_delta_arr + std_factor * std_delta_arr \n",
    "lscalar = mean_delta_arr - std_factor * std_delta_arr \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get the index of the elements whose values are gt hscalar or lt lscalar\n",
    "#IMPORTANT!!: add a + 1 on the row index as we are going to delete the values from the main ndarray and not from delta_arr\n",
    "\n",
    "outliers = np.where((delta_arr <= lscalar) | (delta_arr >= hscalar))\n",
    "coordinates = list(zip(outliers[0], outliers[1]))\n"
   ]
  },
  {
   "source": [
    "To consider: The delta_arr matrix has 1 row less than the original P_arr matrix, because of that, we must add 1 unit to the coordinates of the outliers obtained on the previous selection to access the original outlier coming from P_arr. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new list to store the real outliers\n",
    "coord_v2 = list()\n",
    "\n",
    "for i in range(len(coordinates)):\n",
    "\n",
    "    #check the next value from the first outliers list comparing it with the lscalar\n",
    "\n",
    "    if delta_arr[(coordinates[i][0]+1, coordinates[i][1])] <= lscalar[coordinates[i][1]]:\n",
    "\n",
    "        #check for differences on the signs between values, if they differ, add the loc to the new list\n",
    "        if np.sign(delta_arr[(coordinates[i][0], coordinates[i][1])]) != np.sign(delta_arr[(coordinates[i][0]+1, coordinates[i][1])]):\n",
    "\n",
    "            coord_v2.append((coordinates[i][0]+1, coordinates[i][1]))\n",
    "\n",
    "    #check the next value from the first outliers list comparing it with the hscalar\n",
    "    elif delta_arr[(coordinates[i][0]+1, coordinates[i][1])] >= hscalar[coordinates[i][1]]:\n",
    "\n",
    "        #check for differences on the signs between values, if they differ, add the loc to the new list\n",
    "        if np.sign(delta_arr[(coordinates[i][0], coordinates[i][1])]) != np.sign(delta_arr[(coordinates[i][0]+1, coordinates[i][1])]):\n",
    "\n",
    "            coord_v2.append((coordinates[i][0]+1, coordinates[i][1]))\n",
    "    else:\n",
    "        \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total fields in the matrix: 350640\n"
     ]
    }
   ],
   "source": [
    "#Total qty of data in the matrix\n",
    "t_datos = P_arr.shape[0] * P_arr.shape[1]\n",
    "print('Total fields in the matrix: {}'.format(t_datos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total qty of nan in the matrix: 117859\nPercentage of NaN for this matrix: 33.61%\n"
     ]
    }
   ],
   "source": [
    "#Total qty of nan in the matrix\n",
    "t_nan = np.isnan(P_arr).sum()\n",
    "print('Total qty of nan in the matrix: {}'.format(t_nan))\n",
    "print('Percentage of NaN for this matrix: {0:.2f}%'.format((t_nan/t_datos)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total qty of data in the matrix: 232781\n"
     ]
    }
   ],
   "source": [
    "#total qty of \n",
    "t_real = t_datos - t_nan\n",
    "print('Total qty of data in the matrix: {}'.format(t_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Qty of data removed: 568 or 0.24% from the total of real data.\n"
     ]
    }
   ],
   "source": [
    "#data removed\n",
    "\n",
    "data_to_remove = len(coord_v2)/(t_real)\n",
    "print('Qty of data removed: {} or {:.2f}% from the total of real data.'.format(len(coord_v2), data_to_remove*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimination of outliers\n",
    "for i in range(len(coord_v2)):\n",
    "    P_arr[coord_v2[i]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     AGU     ATM     CEN     LDO  LPIN     MIR     OBL     SFE     TLA    VAL\n",
       "0  49.92  146.95   86.12  174.04   NaN   69.75  197.67  115.54  143.40  17.08\n",
       "1  52.80     NaN   46.49  115.27   NaN   68.99  138.09   84.24  100.46  29.15\n",
       "2  52.71  113.44   63.93   99.00   NaN  117.70   98.79  135.39   82.05  30.89\n",
       "3  51.24   73.30   60.75   83.65   NaN  160.30   97.94  117.60  114.74  38.74\n",
       "4  58.84   52.55  108.09   49.70   NaN  180.89  134.39  164.68  118.83  51.48"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGU</th>\n      <th>ATM</th>\n      <th>CEN</th>\n      <th>LDO</th>\n      <th>LPIN</th>\n      <th>MIR</th>\n      <th>OBL</th>\n      <th>SFE</th>\n      <th>TLA</th>\n      <th>VAL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>49.92</td>\n      <td>146.95</td>\n      <td>86.12</td>\n      <td>174.04</td>\n      <td>NaN</td>\n      <td>69.75</td>\n      <td>197.67</td>\n      <td>115.54</td>\n      <td>143.40</td>\n      <td>17.08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>52.80</td>\n      <td>NaN</td>\n      <td>46.49</td>\n      <td>115.27</td>\n      <td>NaN</td>\n      <td>68.99</td>\n      <td>138.09</td>\n      <td>84.24</td>\n      <td>100.46</td>\n      <td>29.15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>52.71</td>\n      <td>113.44</td>\n      <td>63.93</td>\n      <td>99.00</td>\n      <td>NaN</td>\n      <td>117.70</td>\n      <td>98.79</td>\n      <td>135.39</td>\n      <td>82.05</td>\n      <td>30.89</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>51.24</td>\n      <td>73.30</td>\n      <td>60.75</td>\n      <td>83.65</td>\n      <td>NaN</td>\n      <td>160.30</td>\n      <td>97.94</td>\n      <td>117.60</td>\n      <td>114.74</td>\n      <td>38.74</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>58.84</td>\n      <td>52.55</td>\n      <td>108.09</td>\n      <td>49.70</td>\n      <td>NaN</td>\n      <td>180.89</td>\n      <td>134.39</td>\n      <td>164.68</td>\n      <td>118.83</td>\n      <td>51.48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "#New df with outliers removed\n",
    "processed_P_df = pd.DataFrame(columns=P_df.columns.values, data=P_arr)\n",
    "processed_P_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       AGU     ATM     CEN     LDO   LPIN     MIR     OBL  \\\n",
       "FECHAHORA                                                                   \n",
       "2016-01-01 00:00:00  49.92  146.95   86.12  174.04    NaN   69.75  197.67   \n",
       "2016-01-01 01:00:00  52.80     NaN   46.49  115.27    NaN   68.99  138.09   \n",
       "2016-01-01 02:00:00  52.71  113.44   63.93   99.00    NaN  117.70   98.79   \n",
       "2016-01-01 03:00:00  51.24   73.30   60.75   83.65    NaN  160.30   97.94   \n",
       "2016-01-01 04:00:00  58.84   52.55  108.09   49.70    NaN  180.89  134.39   \n",
       "...                    ...     ...     ...     ...    ...     ...     ...   \n",
       "2019-12-31 19:00:00    NaN   18.10   22.27   84.00   46.2     NaN     NaN   \n",
       "2019-12-31 20:00:00    NaN     NaN   27.51   84.40   57.4     NaN     NaN   \n",
       "2019-12-31 21:00:00    NaN     NaN   28.60   75.30  151.5     NaN     NaN   \n",
       "2019-12-31 22:00:00    NaN     NaN   50.43  125.60  174.2     NaN     NaN   \n",
       "2019-12-31 23:00:00    NaN   58.20   66.09  141.50  144.3     NaN     NaN   \n",
       "\n",
       "                         SFE     TLA    VAL       FECHA      HORA  \n",
       "FECHAHORA                                                          \n",
       "2016-01-01 00:00:00  115.540  143.40  17.08  2016-01-01  00:00:00  \n",
       "2016-01-01 01:00:00   84.240  100.46  29.15  2016-01-01  01:00:00  \n",
       "2016-01-01 02:00:00  135.390   82.05  30.89  2016-01-01  02:00:00  \n",
       "2016-01-01 03:00:00  117.600  114.74  38.74  2016-01-01  03:00:00  \n",
       "2016-01-01 04:00:00  164.680  118.83  51.48  2016-01-01  04:00:00  \n",
       "...                      ...     ...    ...         ...       ...  \n",
       "2019-12-31 19:00:00   55.101   12.68  16.20  2019-12-31  19:00:00  \n",
       "2019-12-31 20:00:00  114.590   50.31  14.00  2019-12-31  20:00:00  \n",
       "2019-12-31 21:00:00  134.160    6.86  22.90  2019-12-31  21:00:00  \n",
       "2019-12-31 22:00:00  212.100  113.16  32.10  2019-12-31  22:00:00  \n",
       "2019-12-31 23:00:00  215.000  113.39  39.00  2019-12-31  23:00:00  \n",
       "\n",
       "[35064 rows x 12 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGU</th>\n      <th>ATM</th>\n      <th>CEN</th>\n      <th>LDO</th>\n      <th>LPIN</th>\n      <th>MIR</th>\n      <th>OBL</th>\n      <th>SFE</th>\n      <th>TLA</th>\n      <th>VAL</th>\n      <th>FECHA</th>\n      <th>HORA</th>\n    </tr>\n    <tr>\n      <th>FECHAHORA</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2016-01-01 00:00:00</th>\n      <td>49.92</td>\n      <td>146.95</td>\n      <td>86.12</td>\n      <td>174.04</td>\n      <td>NaN</td>\n      <td>69.75</td>\n      <td>197.67</td>\n      <td>115.540</td>\n      <td>143.40</td>\n      <td>17.08</td>\n      <td>2016-01-01</td>\n      <td>00:00:00</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 01:00:00</th>\n      <td>52.80</td>\n      <td>NaN</td>\n      <td>46.49</td>\n      <td>115.27</td>\n      <td>NaN</td>\n      <td>68.99</td>\n      <td>138.09</td>\n      <td>84.240</td>\n      <td>100.46</td>\n      <td>29.15</td>\n      <td>2016-01-01</td>\n      <td>01:00:00</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 02:00:00</th>\n      <td>52.71</td>\n      <td>113.44</td>\n      <td>63.93</td>\n      <td>99.00</td>\n      <td>NaN</td>\n      <td>117.70</td>\n      <td>98.79</td>\n      <td>135.390</td>\n      <td>82.05</td>\n      <td>30.89</td>\n      <td>2016-01-01</td>\n      <td>02:00:00</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 03:00:00</th>\n      <td>51.24</td>\n      <td>73.30</td>\n      <td>60.75</td>\n      <td>83.65</td>\n      <td>NaN</td>\n      <td>160.30</td>\n      <td>97.94</td>\n      <td>117.600</td>\n      <td>114.74</td>\n      <td>38.74</td>\n      <td>2016-01-01</td>\n      <td>03:00:00</td>\n    </tr>\n    <tr>\n      <th>2016-01-01 04:00:00</th>\n      <td>58.84</td>\n      <td>52.55</td>\n      <td>108.09</td>\n      <td>49.70</td>\n      <td>NaN</td>\n      <td>180.89</td>\n      <td>134.39</td>\n      <td>164.680</td>\n      <td>118.83</td>\n      <td>51.48</td>\n      <td>2016-01-01</td>\n      <td>04:00:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2019-12-31 19:00:00</th>\n      <td>NaN</td>\n      <td>18.10</td>\n      <td>22.27</td>\n      <td>84.00</td>\n      <td>46.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>55.101</td>\n      <td>12.68</td>\n      <td>16.20</td>\n      <td>2019-12-31</td>\n      <td>19:00:00</td>\n    </tr>\n    <tr>\n      <th>2019-12-31 20:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>27.51</td>\n      <td>84.40</td>\n      <td>57.4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>114.590</td>\n      <td>50.31</td>\n      <td>14.00</td>\n      <td>2019-12-31</td>\n      <td>20:00:00</td>\n    </tr>\n    <tr>\n      <th>2019-12-31 21:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.60</td>\n      <td>75.30</td>\n      <td>151.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>134.160</td>\n      <td>6.86</td>\n      <td>22.90</td>\n      <td>2019-12-31</td>\n      <td>21:00:00</td>\n    </tr>\n    <tr>\n      <th>2019-12-31 22:00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50.43</td>\n      <td>125.60</td>\n      <td>174.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>212.100</td>\n      <td>113.16</td>\n      <td>32.10</td>\n      <td>2019-12-31</td>\n      <td>22:00:00</td>\n    </tr>\n    <tr>\n      <th>2019-12-31 23:00:00</th>\n      <td>NaN</td>\n      <td>58.20</td>\n      <td>66.09</td>\n      <td>141.50</td>\n      <td>144.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>215.000</td>\n      <td>113.39</td>\n      <td>39.00</td>\n      <td>2019-12-31</td>\n      <td>23:00:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>35064 rows Ã— 12 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# add date and time values\n",
    "processed_P_df['FECHA'] = raw_P_df['FECHA']\n",
    "processed_P_df['HORA'] = raw_P_df['HORA']\n",
    "processed_P_df['FECHAHORA'] = raw_P_df['FECHAHORA']\n",
    "processed_P_df.set_index('FECHAHORA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}